{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17489182",
   "metadata": {},
   "source": [
    "# Continous Assessment - 2\n",
    "\n",
    "### Transportation Sector\n",
    "##### Aviation\n",
    "\n",
    "It is critical that Irish aviation practices and procedures comply with best international standards; promoting the development of a vibrant, competitive and progressively regulated aviation sector and the provision of adequate airport infrastructure and competitive airport services.\n",
    "\n",
    "##### Ireland's aviation policy is centred around three main aims:\n",
    "\n",
    "- To enhance Ireland’s connectivity by ensuring safe, secure and competitive access responsive to the needs of business, tourism and consumers.\n",
    "- To foster the growth of aviation enterprise in Ireland to support job creation and position Ireland as a recognised global leader in aviation.\n",
    "- To maximise the contribution of the aviation sector to Ireland’s economic growth and development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e473a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from sodapy import Socrata\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.transform import dodge\n",
    "\n",
    "# Define filenames\n",
    "ireland_dataset_filename1 = 'TAA02.20240102175208.csv'\n",
    "ireland_dataset_filename2 = 'TAA03.20240102175407.csv'\n",
    "\n",
    "# Specify data types for memory efficiency\n",
    "dtypes_ireland = { 'C02191V03548': 'category', 'C02191V04000': 'category', 'STATISTIC': 'category', 'Statistic Label': 'category', 'TLIST(A1)': 'category', 'C02935V03550': 'category', 'C02354V02832': 'category', 'C02936V03551': 'category' }\n",
    "\n",
    "# Load datasets efficiently\n",
    "ireland_dataset_1 = pd.read_csv(ireland_dataset_filename1, dtype=dtypes_ireland, usecols=lambda column: column not in ['C02191V03548', 'C02191V04000', 'STATISTIC', 'Statistic Label', 'TLIST(A1)', 'C02935V03550', 'C02354V02832', 'C02936V03551'])\n",
    "ireland_dataset_2 = pd.read_csv(ireland_dataset_filename2, dtype=dtypes_ireland, usecols=lambda column: column not in ['C02191V03548', 'C02191V04000', 'STATISTIC', 'Statistic Label', 'TLIST(A1)', 'C02935V03550', 'C02354V02832', 'C02936V03551'])\n",
    "\n",
    "# Combine Ireland datasets\n",
    "combined_ireland_dataset = pd.concat([ireland_dataset_1, ireland_dataset_2], ignore_index=True)\n",
    "\n",
    "# Load LA dataset using Socrata client\n",
    "client = Socrata(\"data.lacity.org\", None)\n",
    "results = client.get(\"d3a2-7j6v\", limit=2011)\n",
    "la_flights_dataset = pd.DataFrame.from_records(results)\n",
    "\n",
    "# Optimize data types for LA dataset\n",
    "dtypes_la = { 'reportperiod': 'str', 'passenger_count': 'int32' }\n",
    "la_flights_dataset = la_flights_dataset.astype(dtypes_la)\n",
    "\n",
    "# Convert 'reportperiod' to datetime and extract month and year\n",
    "la_flights_dataset['reportperiod'] = pd.to_datetime(la_flights_dataset['reportperiod'])\n",
    "la_flights_dataset['month'] = la_flights_dataset['reportperiod'].dt.month.astype('int8')\n",
    "la_flights_dataset['year'] = la_flights_dataset['reportperiod'].dt.year.astype('int16')\n",
    "\n",
    "# Data Engineering for Ireland Dataset\n",
    "combined_ireland_dataset['VALUE'] = combined_ireland_dataset['VALUE'].astype('float32')\n",
    "combined_ireland_dataset['passenger_millions'] = combined_ireland_dataset['VALUE'] / 1000\n",
    "\n",
    "# Min-Max Normalization\n",
    "scaler = MinMaxScaler()\n",
    "ireland_passenger_values = combined_ireland_dataset['passenger_millions'].values.reshape(-1, 1)\n",
    "la_passenger_values = la_flights_dataset['passenger_count'].values.reshape(-1, 1)\n",
    "\n",
    "scaler.fit(ireland_passenger_values)\n",
    "combined_ireland_dataset['scaled_passenger_millions'] = scaler.transform(ireland_passenger_values)\n",
    "la_flights_dataset['scaled_passenger_count'] = scaler.transform(la_passenger_values) / 1_000_000\n",
    "\n",
    "# Clean up to free memory\n",
    "del ireland_dataset_1, ireland_dataset_2, ireland_passenger_values, la_passenger_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8eff6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1. Efficient EDA\n",
    "# It's more efficient to view the info and describe outputs directly rather than storing them in variables\n",
    "print(\"LA Flights Dataset Info:\")\n",
    "la_flights_dataset.info()\n",
    "\n",
    "print(\"\\nLA Flights Dataset Describe:\")\n",
    "print(la_flights_dataset.describe())\n",
    "\n",
    "print(\"\\nIreland Dataset Info:\")\n",
    "combined_ireland_dataset.info()\n",
    "\n",
    "print(\"\\nIreland Dataset Describe:\")\n",
    "print(combined_ireland_dataset.describe())\n",
    "\n",
    "# 2. Identifying and Addressing Outliers\n",
    "# Using .clip() method for efficiency\n",
    "lower_bound_la, upper_bound_la = la_flights_dataset['passenger_count'].quantile([0.25, 0.75])\n",
    "IQR_la = upper_bound_la - lower_bound_la\n",
    "la_flights_filtered = la_flights_dataset.copy()\n",
    "la_flights_filtered['passenger_count'] = la_flights_filtered['passenger_count'].clip(lower=lower_bound_la - 1.5 * IQR_la, upper=upper_bound_la + 1.5 * IQR_la)\n",
    "\n",
    "# Similar process for Ireland dataset\n",
    "ireland_filtered = combined_ireland_dataset.copy()\n",
    "lower_bound_ireland, upper_bound_ireland = combined_ireland_dataset['VALUE'].quantile([0.25, 0.75])\n",
    "IQR_ireland = upper_bound_ireland - lower_bound_ireland\n",
    "ireland_filtered['VALUE'] = ireland_filtered['VALUE'].clip(lower=lower_bound_ireland - 1.5 * IQR_ireland, upper=upper_bound_ireland + 1.5 * IQR_ireland)\n",
    "\n",
    "# 3. Efficient Boxplot Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Boxplot for LA Flights Dataset - Before and After Removing Outliers\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=la_flights_dataset['passenger_count'])\n",
    "plt.title('LA Flights - Before Removing Outliers')\n",
    "plt.ylabel('Passenger Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=la_flights_filtered['passenger_count'])\n",
    "plt.title('LA Flights - After Removing Outliers')\n",
    "plt.ylabel('Passenger Count')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Similar boxplot for Ireland dataset\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=ireland_filtered['VALUE'])\n",
    "plt.title('Ireland Dataset - Before Removing Outliers')\n",
    "plt.ylabel('Passenger Value')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=ireland_filtered['VALUE'])\n",
    "plt.title('Ireland Dataset - After Removing Outliers')\n",
    "plt.ylabel('Passenger Value')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Efficient Aggregation and Visualization\n",
    "# Aggregating LA data on a yearly basis\n",
    "la_yearly = la_flights_filtered.groupby('year')['scaled_passenger_count'].mean()\n",
    "\n",
    "# Aggregating Ireland data on a yearly basis\n",
    "ireland_yearly = ireland_filtered.groupby('Year')['scaled_passenger_millions'].mean()\n",
    "\n",
    "# Creating a combined DataFrame for comparison\n",
    "combined_yearly = pd.DataFrame({\n",
    "    'year': ireland_yearly.index,\n",
    "    'Passengers_Ireland': ireland_yearly.values,\n",
    "    'Passengers_LA': la_yearly.values \n",
    "})\n",
    "\n",
    "# Plotly Line Chart for Yearly Comparison\n",
    "fig = px.line(combined_yearly, x='year', y=['Passengers_Ireland', 'Passengers_LA'],\n",
    "              labels={'value': 'Total Passengers', 'variable': 'Location'},\n",
    "              title='Yearly Passenger Trends Comparison: Ireland vs LA (Scaled)')\n",
    "fig.show()\n",
    "\n",
    "# 6. Efficient Categorical Data Analysis\n",
    "# Summarizing and plotting flight types for both datasets\n",
    "ireland_flight_type = ireland_filtered['Flight Type'].value_counts()\n",
    "la_flight_type = la_flights_filtered['flighttype'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Ireland Flight Types\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=ireland_flight_type.index, y=ireland_flight_type.values)\n",
    "plt.title('Ireland Flight Types')\n",
    "plt.xlabel('Flight Type')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# LA Flight Types\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=la_flight_type.index, y=la_flight_type.values)\n",
    "plt.title('LA Flight Types')\n",
    "plt.xlabel('Flight Type')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizing Scaled Passenger Traffic\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=ireland_filtered['scaled_passenger_millions'])\n",
    "plt.title('Ireland Passenger Traffic Distribution')\n",
    "plt.ylabel('Passenger Count (Thousands)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=la_flights_filtered['scaled_passenger_count']*10)\n",
    "plt.title('LA Passenger Traffic Distribution')\n",
    "plt.ylabel('Passenger Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Flight Type Distribution in Ireland\n",
    "fig = px.bar(ireland_flight_type, title='Flight Type Distribution in Ireland')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19453e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTIC ANALYSIS\n",
    "\n",
    "# For Ireland - Confidence Interval calculation for top countries\n",
    "top_countries = ireland_filtered['Country'].value_counts().head(5).index\n",
    "confidence_intervals_ireland = {}\n",
    "z_score = stats.norm.ppf(0.975)  # for a 95% confidence level\n",
    "\n",
    "for country in top_countries:\n",
    "    country_data = ireland_filtered[ireland_filtered['Country'] == country]['scaled_passenger_millions']\n",
    "    mean, std_error = np.mean(country_data), stats.sem(country_data, nan_policy='omit')\n",
    "    margin_of_error = z_score * std_error\n",
    "    confidence_intervals_ireland[country] = (mean - margin_of_error, mean + margin_of_error)\n",
    "\n",
    "# For LA - Confidence Interval calculation for flight types\n",
    "flight_types = ['Domestic', 'International']\n",
    "confidence_intervals_la = {}\n",
    "\n",
    "for flight_type in flight_types:\n",
    "    flight_data = la_flights_dataset[la_flights_dataset['domestic_international'] == flight_type]['scaled_passenger_count']\n",
    "    mean, std_error = np.mean(flight_data), stats.sem(flight_data, nan_policy='omit')\n",
    "    margin_of_error = z_score * std_error\n",
    "    confidence_intervals_la[flight_type] = (mean - margin_of_error, mean + margin_of_error)\n",
    "\n",
    "# ANOVA for yearly trends in flight traffic - Ireland\n",
    "anova_model_ireland = ols('VALUE ~ C(Year)', data=ireland_filtered).fit()\n",
    "anova_results_ireland = sm.stats.anova_lm(anova_model_ireland, typ=2)\n",
    "\n",
    "# ANOVA for differences in passenger count among flight types - LA\n",
    "anova_model_la = ols('passenger_count ~ C(flighttype)', data=la_flights_dataset).fit()\n",
    "anova_results_la = sm.stats.anova_lm(anova_model_la, typ=2)\n",
    "\n",
    "# Chi-Squared Test for Ireland: 'Flight Type' vs 'Direction'\n",
    "contingency_table_ireland = pd.crosstab(ireland_filtered['Flight Type'], ireland_filtered['Direction'])\n",
    "chi2_ireland, p_ireland, dof_ireland, expected_ireland = chi2_contingency(contingency_table_ireland)\n",
    "\n",
    "# Chi-Squared Test for LA: 'Domestic_International' vs 'Arrival_Departure'\n",
    "contingency_table_la = pd.crosstab(la_flights_dataset['domestic_international'], la_flights_dataset['arrival_departure'])\n",
    "chi2_la, p_la, dof_la, expected_la = chi2_contingency(contingency_table_la)\n",
    "\n",
    "# Independent Samples T-Test - Comparison between 2010 and 2015 for Ireland\n",
    "data_2010_ireland = ireland_filtered[ireland_filtered['Year'] == 2010]['VALUE']\n",
    "data_2015_ireland = ireland_filtered[ireland_filtered['Year'] == 2015]['VALUE']\n",
    "t_stat_ireland, p_value_ireland = stats.ttest_ind(data_2010_ireland, data_2015_ireland, equal_var=False)\n",
    "\n",
    "# Independent Samples T-Test - Comparison between 2010 and 2015 for LA\n",
    "data_2010_la = la_flights_dataset[la_flights_dataset['year'] == 2010]['passenger_count']\n",
    "data_2015_la = la_flights_dataset[la_flights_dataset['year'] == 2015]['passenger_count']\n",
    "t_stat_la, p_value_la = stats.ttest_ind(data_2010_la, data_2015_la, equal_var=False)\n",
    "\n",
    "# One-Sample T-Test for LA - 2010 vs Hypothesized Mean\n",
    "hypothesized_mean_la = 600000  # example value\n",
    "t_stat_one_sample_la, p_value_one_sample_la = stats.ttest_1samp(data_2010_la, hypothesized_mean_la)\n",
    "\n",
    "# Wilcoxon Signed-Rank Test for LA - Comparison between 2018 and 2019\n",
    "data_2018_la = la_flights_dataset[la_flights_dataset['year'] == 2018]['passenger_count']\n",
    "data_2019_la = la_flights_dataset[la_flights_dataset['year'] == 2019]['passenger_count']\n",
    "min_length_la = min(len(data_2018_la), len(data_2019_la))\n",
    "data_2018_la_sampled = data_2018_la.sample(n=min_length_la, random_state=1)\n",
    "data_2019_la_sampled = data_2019_la.sample(n=min_length_la, random_state=1)\n",
    "w_stat_la, p_value_wilcoxon_la = stats.wilcoxon(data_2018_la_sampled, data_2019_la_sampled)\n",
    "\n",
    "# Store the results in a dictionary for easy access and display\n",
    "results = {\n",
    "    'Confidence Intervals Ireland': confidence_intervals_ireland,\n",
    "    'Confidence Intervals LA': confidence_intervals_la,\n",
    "    'ANOVA Ireland': anova_results_ireland,\n",
    "    'ANOVA LA': anova_results_la,\n",
    "    'Chi-Squared Ireland': (chi2_ireland, p_ireland, dof_ireland, expected_ireland),\n",
    "    'Chi-Squared LA': (chi2_la, p_la, dof_la, expected_la),\n",
    "    'T-Test Ireland': (t_stat_ireland, p_value_ireland),\n",
    "    'T-Test LA': (t_stat_la, p_value_la),\n",
    "    'One-Sample T-Test LA': (t_stat_one_sample_la, p_value_one_sample_la),\n",
    "    'Wilcoxon Test LA': (w_stat_la, p_value_wilcoxon_la)\n",
    "}\n",
    "\n",
    "# Display results\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: \\n{value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364d180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MACHINE LEARNING BULDING AND TRAINING\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Dropping unnecessary columns\n",
    "ireland_cleaned = ireland_filtered.drop(columns=[\"UNIT\"])\n",
    "\n",
    "# Aggregating data by year\n",
    "data_yearly = ireland_cleaned.groupby(['Year', 'Airports in Ireland', 'Country', 'Direction', 'Flight Type']).agg({'VALUE': 'sum', 'passenger_millions': 'sum', 'scaled_passenger_millions': 'sum'}).reset_index()\n",
    "\n",
    "# Encoding categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=True)  # Use sparse_output for memory efficiency\n",
    "encoded_columns = encoder.fit_transform(data_yearly[['Airports in Ireland', 'Country', 'Direction', 'Flight Type']])\n",
    "encoded_df = pd.DataFrame.sparse.from_spmatrix(encoded_columns, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Merging the encoded columns with the original data\n",
    "data_prepared = pd.concat([data_yearly, encoded_df], axis=1).drop(['Airports in Ireland', 'Country', 'Direction', 'Flight Type'], axis=1)\n",
    "\n",
    "# Defining the features and target variable\n",
    "X = data_prepared.drop(['VALUE', 'scaled_passenger_millions', 'scaled_passenger_millions'], axis=1)\n",
    "y = data_prepared['passenger_millions']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Neural Network\": MLPRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    model_performance = {}\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse, mae = mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred)\n",
    "        model_performance[model_name] = {'MSE': mse, 'RMSE': np.sqrt(mse), 'MAE': mae}\n",
    "    return model_performance\n",
    "\n",
    "model_performance = train_evaluate_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Hyperparameter tuning for Gradient Boosting Regressor\n",
    "param_grid_gbr = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "grid_search_gbr = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid=param_grid_gbr, cv=3, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "grid_search_gbr.fit(X_train, y_train)\n",
    "best_params_gbr, best_score_gbr = grid_search_gbr.best_params_, grid_search_gbr.best_score_\n",
    "\n",
    "# Predicting with the best estimator from Gradient Boosting Regressor\n",
    "y_pred_gbr = grid_search_gbr.predict(X_test)\n",
    "mse_gbr, rmse_gbr, mae_gbr = mean_squared_error(y_test, y_pred_gbr), np.sqrt(mean_squared_error(y_test, y_pred_gbr)), mean_absolute_error(y_test, y_pred_gbr)\n",
    "\n",
    "\n",
    "# Hyperparameter tuning for Random Forest Regressor\n",
    "param_distributions_rfr = {'n_estimators': randint(100, 1000), 'max_depth': randint(10, 100), 'min_samples_split': randint(2, 20), 'min_samples_leaf': randint(1, 20)}\n",
    "random_search_rfr = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_distributions=param_distributions_rfr, n_iter=5, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_rfr.fit(X_train, y_train)\n",
    "best_params_rfr, best_score_rfr = random_search_rfr.best_params_, random_search_rfr.best_score_\n",
    "\n",
    "# Predicting with the best estimator from Random Forest Regressor\n",
    "y_pred_rfr = random_search_rfr.predict(X_test)\n",
    "mse_rfr, rmse_rfr, mae_rfr = mean_squared_error(y_test, y_pred_rfr), np.sqrt(mean_squared_error(y_test, y_pred_rfr)), mean_absolute_error(y_test, y_pred_rfr)\n",
    "\n",
    "\n",
    "# Hyperparameter tuning for Neural Network with Pipeline\n",
    "pipeline_nn = Pipeline([('scaler', StandardScaler()), ('nn', MLPRegressor(random_state=42))])\n",
    "param_grid_nn = {'nn__hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)], 'nn__activation': ['tanh', 'relu'], 'nn__solver': ['sgd', 'adam'], 'nn__alpha': [0.0001, 0.05], 'nn__learning_rate': ['constant','adaptive']}\n",
    "grid_search_nn = GridSearchCV(pipeline_nn, param_grid=param_grid_nn, n_jobs=-1, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search_nn.fit(X_train, y_train)\n",
    "best_params_nn, best_score_nn = grid_search_nn.best_params_, grid_search_nn.best_score_\n",
    "\n",
    "# Predicting with the best estimator from Neural Network\n",
    "y_pred_nn = grid_search_nn.predict(X_test)\n",
    "mse_nn, rmse_nn, mae_nn = mean_squared_error(y_test, y_pred_nn), np.sqrt(mean_squared_error(y_test, y_pred_nn)), mean_absolute_error(y_test, y_pred_nn)\n",
    "\n",
    "# Bokeh Visualization\n",
    "output_notebook()\n",
    "\n",
    "# Data\n",
    "models = ['Random Forest', 'Gradient Boosting', 'Neural Network']\n",
    "tuning = ['Before Tuning', 'After Tuning']\n",
    "metrics = ['MSE', 'RMSE', 'MAE']]\n",
    "\n",
    "#Scores are inputed in after fitting the models with best parameters\n",
    "data = {'models': models,\n",
    "        'MSE_Before': [5.612700496991892e-09, 1.339954113112935e-08, 0.42458051830968135],\n",
    "        'MSE_After': [6.205090760614536e-09, 9.765209701455155e-09, 0.0020245364790739497],\n",
    "        'RMSE_Before': [7.491795844116344e-05, 0.0001157563869992898, 0.651598433323532],\n",
    "        'RMSE_After': [7.877239846935306e-05, 9.881907559502444e-05, 0.04499484947273354],\n",
    "        'MAE_Before': [3.328154154677827e-05, 7.481326086241598e-05, 0.6503566495043961],\n",
    "        'MAE_After': [3.802027503408869e-05, 6.10729539431655e-05, 0.04487710380099862]}\n",
    "\n",
    "# Preparing the data\n",
    "source = ColumnDataSource(data=data)\n",
    "\n",
    "# Creating the plot\n",
    "p = figure(x_range=models, outer_height=350, title=\"Model Performance Metrics Before and After Tuning\",\n",
    "           toolbar_location=None, tools=\"\")\n",
    "\n",
    "width = 0.2\n",
    "for idx, metric in enumerate(metrics):\n",
    "    p.vbar(x=dodge('models', -0.25 + idx * width, range=p.x_range), top=f'{metric}_Before', width=width, \n",
    "           source=source, color=\"#718dbf\", legend_label=f'{metric} Before')\n",
    "    p.vbar(x=dodge('models', -0.05 + idx * width, range=p.x_range), top=f'{metric}_After', width=width, \n",
    "           source=source, color=\"#e84d60\", legend_label=f'{metric} After')\n",
    "\n",
    "p.x_range.range_padding = 0.1\n",
    "p.xgrid.grid_line_color = None\n",
    "p.legend.location = \"top_left\"\n",
    "p.legend.orientation = \"horizontal\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52b436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
